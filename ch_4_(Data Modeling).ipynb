{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 모델링\n",
    "- 빅데이터 분야에서 모델링은 데이터를 설명할 수 있는 모델(ML/DL)을 만드는 것을 말한다.\n",
    "\n",
    "- 일반적인 빅데이터 프로젝트 절차\n",
    "    - 목표 설정\n",
    "    - 데이터 수집 (web, txt, img, machine data ...)\n",
    "    - 데이터 전처리 (이 부분이 전체 프로젝트에 80% 이상)\n",
    "    - 데이터 시각화\n",
    "    - 모델링 (모델 생성 -> 모델 평가)\n",
    "    - 모델 적용\n",
    "    - 유지관리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scikit-Learn 라이브러리\n",
    "- scikit-learn 은 파이썬으로 작성된 데이터 모델링을 위한 범용 오픈 소스 라이브러리\n",
    "- 분류, 회위, 군집화, 의사결정나부 등의 다양한 머신러닝 알고리즘을 적용할 수 있는 함수를 제공\n",
    "\n",
    "- 공식 홈페이지 : https://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iris(붓꽃) 데이터\n",
    "- https://en.wikipedia.org/wiki/Iris_flower_data_set 참조\n",
    "- 1936년 한 영국 통계학자에 의해 선형분류 문제의 예제로 활용되면서 머신러닝의 대표적인 예제로 활용되고 있다.\n",
    "- 속성 : 꽃받침 길이(sepal length), 꽃받침 폭(sepal width), 꽃잎 길이(petal length), 꽃잎 폭(petal width)\n",
    "- 타겟값(목표값) : setosa, versicolor, verginica\n",
    "- 샘플 갯수 : 150개 (세품종 각각 50개씩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris  # 자주 사용하는 자료라 함수가 사이킷 런에 들어있기 때문에 이렇게 로드할 수 있다.\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# loadtxt이므로 iris.data와 같은 형식으로 쓴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(iris.target, iris.target.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(iris.target[iris.target==0].shape, iris.target[iris.target==1].shape, iris.target[iris.target==2].shape)\n",
    "# 줄 단위로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(iris.data.shape, iris.data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련세트와 테스트세트로 분리\n",
    "    - 머신러닝은 훈련 과정과 테스트 과정 두가지로 분리된다.\n",
    "    - 훈련세트를 가지고 예측모델을 훈련시킨 다음에 테스트세트로 훈련 성과를 판단한다.\n",
    "    - sklearn.model_selection.train_test_split() 함수를 사용하면 편리하게 나눌 수 있다.\n",
    "    - train_test_split() 함수는 기본값으로 훈련세트를 75%, 테스트세트를 25% 로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target)\n",
    "\n",
    "# 데이터를 모두 집어넣어 분석해 모델을 만들 수 있겠지만, 새로운 데이터가 나타나야 그 모델을 테스트 할 수 있다.\n",
    "# 그러므로 모델을 만들때 일부를 남겨두고 모델을 만든다음, 그 남겨진 데이터를 테스트용 데이터로서 사용한다.\n",
    "# train은 훈련용, test 테스트용 75%, 25% 섞어서 랜덤하게(뽑는 방법을 설정할수도 있다.)\n",
    "\n",
    "display(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# 아이리스 데이터가 150x4, 타겟이 150x1인데 데이터를 훈련용으로 112x4, 테스트용으로38x4, 타켓을 훈련용으로 112x1, 테스트용으로 38x1 로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4가지 속성에 대해 산점도 그리기\n",
    "    - 산점도(scatter map)은 두 가지 속성을 가진 데이터를 그래프에 점을 찍어 표시한 그림이다.\n",
    "    - Iris 데이터의 4가지 속성에 대해 짝을 지어 산점도를 그려보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(X_train, columns=iris.feature_names)\n",
    "# DataFrame은 데이타 안에다가 칼럼 이름까지 넣을 수 있다. 인덱스를 자동으로 지정 할 수 있다.\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(iris_df, c=y_train, s=60, alpha=0.8, figsize=[12,12])\n",
    "# scatter_matrix라는 함수를 이용하기 위해서 pandas를 사용했다.\n",
    "# 데이터에서 2개씩 짝지어서 6개의 산점도를 그렸다.\n",
    "# 자기자신은 히스토그램\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest 예측 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 모델 생성\n",
    "model1=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# 모델 학습\n",
    "model1.fit(X_train,y_train)\n",
    "\n",
    "# 모델 평가\n",
    "score = model1.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- k-NN (최근접 이웃) 예측 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 모델 생성\n",
    "model2 = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# 모델 학습\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "print(model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 자동차 연비 예측하기: 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#데이터 읽어오기\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "raw_dataset = pd.read_csv('datasets/auto-mpg.data', names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      sep=\" \", skipinitialspace=True)\n",
    "\n",
    "dataset = raw_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 확인\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치 제거\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#범주형 데이터 처리\n",
    "origin = dataset.pop('Origin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[:,'USA'] = (origin == 1)*1.0\n",
    "dataset.loc[:,'Europe'] = (origin == 2)*1.0\n",
    "dataset.loc[:,'Japan'] = (origin == 3)*1.0\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test datset 분할\n",
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train_dataset.describe()\n",
    "train_stats.pop(\"MPG\")\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('MPG')\n",
    "test_labels = test_dataset.pop('MPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML data 정규화\n",
    "def norm(x):\n",
    "      return (x - train_stats['mean']) / train_stats['std']\n",
    "\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML시작\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 모델 생성\n",
    "model1=RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# 모델 학습\n",
    "model1.fit(normed_train_data,train_labels)\n",
    "\n",
    "# 모델 평가\n",
    "score = model1.score(normed_test_data, test_labels)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_normed_test_data = model1.predict(normed_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=pred_normed_test_data, y=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
